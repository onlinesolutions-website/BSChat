{"ast":null,"code":"import _regeneratorRuntime from\"/Users/jarrettpruitt/Desktop/chatgpt-starter-kit 1.2/client/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";import _toConsumableArray from\"/Users/jarrettpruitt/Desktop/chatgpt-starter-kit 1.2/client/node_modules/@babel/runtime/helpers/esm/toConsumableArray.js\";import _asyncToGenerator from\"/Users/jarrettpruitt/Desktop/chatgpt-starter-kit 1.2/client/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";import _slicedToArray from\"/Users/jarrettpruitt/Desktop/chatgpt-starter-kit 1.2/client/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";import'./normal.css';import'./App.css';import{useState,useEffect}from'react';import SideMenu from'./SideMenu';import ChatBox from'./ChatBox';import{jsx as _jsx}from\"react/jsx-runtime\";import{jsxs as _jsxs}from\"react/jsx-runtime\";function App(){useEffect(function(){getEngines();},[]);var _useState=useState(\"\"),_useState2=_slicedToArray(_useState,2),chatInput=_useState2[0],setChatInput=_useState2[1];var _useState3=useState([]),_useState4=_slicedToArray(_useState3,2),models=_useState4[0],setModels=_useState4[1];var _useState5=useState(0.5),_useState6=_slicedToArray(_useState5,2),temperature=_useState6[0],setTemperature=_useState6[1];var _useState7=useState(\"text-davinci-003\"),_useState8=_slicedToArray(_useState7,2),currentModel=_useState8[0],setCurrentModel=_useState8[1];var _useState9=useState([{user:\"gpt\",message:\"How can I help you today?\"}]),_useState10=_slicedToArray(_useState9,2),chatLog=_useState10[0],setChatLog=_useState10[1];// clear chats\nfunction clearChat(){setChatLog([]);}function getEngines(){fetch(\"http://localhost:3080/models\").then(function(res){return res.json();}).then(function(data){console.log(data.models.data);// set models in order alpahbetically\ndata.models.data.sort(function(a,b){if(a.id<b.id){return-1;}if(a.id>b.id){return 1;}return 0;});setModels(data.models.data);});}function handleSubmit(_x){return _handleSubmit.apply(this,arguments);}function _handleSubmit(){_handleSubmit=_asyncToGenerator(/*#__PURE__*/_regeneratorRuntime().mark(function _callee(e){var chatLogNew,messages,response,data,scrollToTheBottomChatLog;return _regeneratorRuntime().wrap(function _callee$(_context){while(1)switch(_context.prev=_context.next){case 0:e.preventDefault();chatLogNew=[].concat(_toConsumableArray(chatLog),[{user:\"me\",message:\"\".concat(chatInput)}]);setChatInput(\"\");setChatLog(chatLogNew);// fetch response to the api combining the chat log array of messages and seinding it as a message to localhost:3000 as a post\nmessages=chatLogNew.map(function(message){return message.message;}).join(\"\\n\");_context.next=7;return fetch(\"http://localhost:3080/\",{method:\"POST\",headers:{\"Content-Type\":\"application/json\"},body:JSON.stringify({message:messages,currentModel:currentModel})});case 7:response=_context.sent;_context.next=10;return response.json();case 10:data=_context.sent;setChatLog([].concat(_toConsumableArray(chatLogNew),[{user:\"gpt\",message:\"\".concat(data.message)}]));scrollToTheBottomChatLog=document.getElementsByClassName(\"chat-log\")[0];scrollToTheBottomChatLog.scrollTop=scrollToTheBottomChatLog.scrollHeight;case 14:case\"end\":return _context.stop();}},_callee);}));return _handleSubmit.apply(this,arguments);}function handleTemp(temp){if(temp>1){setTemperature(1);}else if(temp<0){setTemperature(0);}else{setTemperature(temp);}}return/*#__PURE__*/_jsxs(\"div\",{className:\"App\",children:[/*#__PURE__*/_jsx(SideMenu,{currentModel:currentModel,setCurrentModel:setCurrentModel,models:models,setTemperature:handleTemp,temperature:temperature,clearChat:clearChat}),/*#__PURE__*/_jsx(ChatBox,{chatInput:chatInput,chatLog:chatLog,setChatInput:setChatInput,handleSubmit:handleSubmit})]});}export default App;","map":{"version":3,"names":["useState","useEffect","SideMenu","ChatBox","App","getEngines","chatInput","setChatInput","models","setModels","temperature","setTemperature","currentModel","setCurrentModel","user","message","chatLog","setChatLog","clearChat","fetch","then","res","json","data","console","log","sort","a","b","id","handleSubmit","e","preventDefault","chatLogNew","messages","map","join","method","headers","body","JSON","stringify","response","scrollToTheBottomChatLog","document","getElementsByClassName","scrollTop","scrollHeight","handleTemp","temp"],"sources":["/Users/jarrettpruitt/Desktop/chatgpt-starter-kit 1.2/client/src/App.js"],"sourcesContent":["import './normal.css';\nimport './App.css';\nimport { useState, useEffect } from 'react';\nimport SideMenu from './SideMenu'\nimport ChatBox from './ChatBox'\n\nfunction App() {\n\n  useEffect(() => {\n    getEngines();\n  }, [])\n\n  const [chatInput, setChatInput] = useState(\"\");\n  const [models, setModels] = useState([]);\n  const [temperature, setTemperature] = useState(0.5);\n  const [currentModel, setCurrentModel] = useState(\"text-davinci-003\");\n  const [chatLog, setChatLog] = useState([{\n    user: \"gpt\",\n    message: \"How can I help you today?\"\n  }]);\n\n  // clear chats\n  function clearChat(){\n    setChatLog([]);\n  }\n\n  function getEngines(){\n    fetch(\"http://localhost:3080/models\")\n    .then(res => res.json())\n    .then(data => {\n      console.log(data.models.data)\n      // set models in order alpahbetically\n      data.models.data.sort((a, b) => {\n        if(a.id < b.id) { return -1; }\n        if(a.id > b.id) { return 1; }\n        return 0;\n      })\n      setModels(data.models.data)\n    })\n  }\n  \n  async function handleSubmit(e){\n    e.preventDefault();\n    let chatLogNew = [...chatLog, { user: \"me\", message: `${chatInput}`} ]\n    setChatInput(\"\");\n    setChatLog(chatLogNew)\n    // fetch response to the api combining the chat log array of messages and seinding it as a message to localhost:3000 as a post\n    const messages = chatLogNew.map((message) => message.message).join(\"\\n\")\n    \n    const response = await fetch(\"http://localhost:3080/\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\"\n      },\n      body: JSON.stringify({\n        message: messages,\n        currentModel,\n       })\n      });\n    const data = await response.json();\n    setChatLog([...chatLogNew, { user: \"gpt\", message: `${data.message}`} ])\n    var scrollToTheBottomChatLog = document.getElementsByClassName(\"chat-log\")[0];\n    scrollToTheBottomChatLog.scrollTop = scrollToTheBottomChatLog.scrollHeight;\n  }\n\n  function handleTemp(temp) {\n    if(temp > 1){\n      setTemperature(1)\n    } else if (temp < 0){\n      setTemperature(0)\n    } else {\n      setTemperature(temp)\n    }\n\n  }\n\n  return (\n    <div className=\"App\">\n      <SideMenu\n        currentModel={currentModel} \n        setCurrentModel={setCurrentModel} \n        models={models}\n        setTemperature={handleTemp}\n        temperature={temperature}\n        clearChat={clearChat}\n      />\n      <ChatBox \n        chatInput={chatInput}\n        chatLog={chatLog} \n        setChatInput={setChatInput} \n        handleSubmit={handleSubmit} />\n    </div>\n  );\n}\n\n\nexport default App;\n"],"mappings":"4lBAAA,MAAO,cAAc,CACrB,MAAO,WAAW,CAClB,OAASA,QAAQ,CAAEC,SAAS,KAAQ,OAAO,CAC3C,MAAOC,SAAQ,KAAM,YAAY,CACjC,MAAOC,QAAO,KAAM,WAAW,yFAE/B,QAASC,IAAG,EAAG,CAEbH,SAAS,CAAC,UAAM,CACdI,UAAU,EAAE,CACd,CAAC,CAAE,EAAE,CAAC,CAEN,cAAkCL,QAAQ,CAAC,EAAE,CAAC,wCAAvCM,SAAS,eAAEC,YAAY,eAC9B,eAA4BP,QAAQ,CAAC,EAAE,CAAC,yCAAjCQ,MAAM,eAAEC,SAAS,eACxB,eAAsCT,QAAQ,CAAC,GAAG,CAAC,yCAA5CU,WAAW,eAAEC,cAAc,eAClC,eAAwCX,QAAQ,CAAC,kBAAkB,CAAC,yCAA7DY,YAAY,eAAEC,eAAe,eACpC,eAA8Bb,QAAQ,CAAC,CAAC,CACtCc,IAAI,CAAE,KAAK,CACXC,OAAO,CAAE,2BACX,CAAC,CAAC,CAAC,0CAHIC,OAAO,gBAAEC,UAAU,gBAK1B;AACA,QAASC,UAAS,EAAE,CAClBD,UAAU,CAAC,EAAE,CAAC,CAChB,CAEA,QAASZ,WAAU,EAAE,CACnBc,KAAK,CAAC,8BAA8B,CAAC,CACpCC,IAAI,CAAC,SAAAC,GAAG,QAAIA,IAAG,CAACC,IAAI,EAAE,GAAC,CACvBF,IAAI,CAAC,SAAAG,IAAI,CAAI,CACZC,OAAO,CAACC,GAAG,CAACF,IAAI,CAACf,MAAM,CAACe,IAAI,CAAC,CAC7B;AACAA,IAAI,CAACf,MAAM,CAACe,IAAI,CAACG,IAAI,CAAC,SAACC,CAAC,CAAEC,CAAC,CAAK,CAC9B,GAAGD,CAAC,CAACE,EAAE,CAAGD,CAAC,CAACC,EAAE,CAAE,CAAE,MAAO,CAAC,CAAC,CAAE,CAC7B,GAAGF,CAAC,CAACE,EAAE,CAAGD,CAAC,CAACC,EAAE,CAAE,CAAE,MAAO,EAAC,CAAE,CAC5B,MAAO,EAAC,CACV,CAAC,CAAC,CACFpB,SAAS,CAACc,IAAI,CAACf,MAAM,CAACe,IAAI,CAAC,CAC7B,CAAC,CAAC,CACJ,CAAC,QAEcO,aAAY,kJAA3B,iBAA4BC,CAAC,kLAC3BA,CAAC,CAACC,cAAc,EAAE,CACdC,UAAU,8BAAOjB,OAAO,GAAE,CAAEF,IAAI,CAAE,IAAI,CAAEC,OAAO,WAAKT,SAAS,CAAE,CAAC,GACpEC,YAAY,CAAC,EAAE,CAAC,CAChBU,UAAU,CAACgB,UAAU,CAAC,CACtB;AACMC,QAAQ,CAAGD,UAAU,CAACE,GAAG,CAAC,SAACpB,OAAO,QAAKA,QAAO,CAACA,OAAO,GAAC,CAACqB,IAAI,CAAC,IAAI,CAAC,uBAEjDjB,MAAK,CAAC,wBAAwB,CAAE,CACrDkB,MAAM,CAAE,MAAM,CACdC,OAAO,CAAE,CACP,cAAc,CAAE,kBAClB,CAAC,CACDC,IAAI,CAAEC,IAAI,CAACC,SAAS,CAAC,CACnB1B,OAAO,CAAEmB,QAAQ,CACjBtB,YAAY,CAAZA,YACD,CAAC,CACF,CAAC,CAAC,QATE8B,QAAQ,sCAUKA,SAAQ,CAACpB,IAAI,EAAE,SAA5BC,IAAI,eACVN,UAAU,8BAAKgB,UAAU,GAAE,CAAEnB,IAAI,CAAE,KAAK,CAAEC,OAAO,WAAKQ,IAAI,CAACR,OAAO,CAAE,CAAC,GAAG,CACpE4B,wBAAwB,CAAGC,QAAQ,CAACC,sBAAsB,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAC7EF,wBAAwB,CAACG,SAAS,CAAGH,wBAAwB,CAACI,YAAY,CAAC,sDAC5E,+CAED,QAASC,WAAU,CAACC,IAAI,CAAE,CACxB,GAAGA,IAAI,CAAG,CAAC,CAAC,CACVtC,cAAc,CAAC,CAAC,CAAC,CACnB,CAAC,IAAM,IAAIsC,IAAI,CAAG,CAAC,CAAC,CAClBtC,cAAc,CAAC,CAAC,CAAC,CACnB,CAAC,IAAM,CACLA,cAAc,CAACsC,IAAI,CAAC,CACtB,CAEF,CAEA,mBACE,aAAK,SAAS,CAAC,KAAK,wBAClB,KAAC,QAAQ,EACP,YAAY,CAAErC,YAAa,CAC3B,eAAe,CAAEC,eAAgB,CACjC,MAAM,CAAEL,MAAO,CACf,cAAc,CAAEwC,UAAW,CAC3B,WAAW,CAAEtC,WAAY,CACzB,SAAS,CAAEQ,SAAU,EACrB,cACF,KAAC,OAAO,EACN,SAAS,CAAEZ,SAAU,CACrB,OAAO,CAAEU,OAAQ,CACjB,YAAY,CAAET,YAAa,CAC3B,YAAY,CAAEuB,YAAa,EAAG,GAC5B,CAEV,CAGA,cAAe1B,IAAG"},"metadata":{},"sourceType":"module","externalDependencies":[]}